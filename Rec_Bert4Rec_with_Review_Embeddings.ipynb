{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a5_JCFX_TGbDmCS7zzUzhg8dc4ee_m6o",
      "authorship_tag": "ABX9TyNxiUWSALkYzcNypHnuYbou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qadooshere/ML-Projects/blob/main/Rec_Bert4Rec_with_Review_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSg-yQZU0MRo",
        "outputId": "2c4db65b-17b1-4a09-df7e-1ef55dd16da9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "x-XtJdISvnIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the necessary libraries\n"
      ],
      "metadata": {
        "id": "QCWGrITWtljD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import ast\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "ejmkDcA1wdPf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "DGkTEDqU32r_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn6O0Rwti75L"
      },
      "outputs": [],
      "source": [
        "# Retrieve the subset Beauty product from the Amazon Reviews dataset and store in CSVs in Drive folder \"generate_embeddings\" (folder must be created in Drive first)\n",
        "dataset = load_dataset(\"amazon_us_reviews\",'Beauty_v1_00')\n",
        "for split, ds in dataset.items():\n",
        "  ds.to_csv(\"/content/drive/MyDrive/bert4rec_generate_embeddings/my-dataset-beauty.csv\", index=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (first 100 rows to speed up)\n",
        "reviews_df = pd.read_csv('/content/drive/MyDrive/bert4rec_generate_embeddings/my-dataset-beauty.csv', nrows = 100)  "
      ],
      "metadata": {
        "id": "Fipe7n3q0U7F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf = reviews_df.copy()  # Create a copy of the existing DataFrame\n"
      ],
      "metadata": {
        "id": "9xOwh7_sYKyj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FXHPCX6Yoz_",
        "outputId": "419bfaa3-2551-4804-998e-7418780b7240"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Pre-trained BERT Model and Tokenizer:\n",
        "\n",
        "The code specifies the name of the pre-trained BERT model to be loaded. In this case, it is set to 'bert-base-uncased'.\n",
        "The BertTokenizer.from_pretrained method is called to load the pre-trained tokenizer corresponding to the specified model name.\n",
        "The BertModel.from_pretrained method is called to load the pre-trained BERT model corresponding to the specified model name.\n",
        "The loaded BERT model is moved to the device specified earlier using .to(device)"
      ],
      "metadata": {
        "id": "X4kMJ1FIt4j5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device for training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGSDTqhEvvbD",
        "outputId": "1b29ada1-2c77-4705-c4a6-06144c1c79b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The conditional expression torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") creates a torch.device object that represents either the GPU (specified as \"cuda\") or the CPU (specified as \"cpu\") depending on the result of torch.cuda.is_available()."
      ],
      "metadata": {
        "id": "RjHoRfkoupS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Dataset"
      ],
      "metadata": {
        "id": "atfkqYmutryp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPHw57qYKO3U",
        "outputId": "cc1c04f8-b739-42bd-8b2a-d1b0f6960c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "marketplace          0\n",
            "customer_id          0\n",
            "review_id            0\n",
            "product_id           0\n",
            "product_parent       0\n",
            "product_title        0\n",
            "product_category     0\n",
            "star_rating          0\n",
            "helpful_votes        0\n",
            "total_votes          0\n",
            "vine                 0\n",
            "verified_purchase    0\n",
            "review_headline      0\n",
            "review_body          0\n",
            "review_date          0\n",
            "dtype: int64 /n\n",
            "Duplication : 0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 15 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   marketplace        100 non-null    object\n",
            " 1   customer_id        100 non-null    int64 \n",
            " 2   review_id          100 non-null    object\n",
            " 3   product_id         100 non-null    object\n",
            " 4   product_parent     100 non-null    int64 \n",
            " 5   product_title      100 non-null    object\n",
            " 6   product_category   100 non-null    object\n",
            " 7   star_rating        100 non-null    int64 \n",
            " 8   helpful_votes      100 non-null    int64 \n",
            " 9   total_votes        100 non-null    int64 \n",
            " 10  vine               100 non-null    int64 \n",
            " 11  verified_purchase  100 non-null    int64 \n",
            " 12  review_headline    100 non-null    object\n",
            " 13  review_body        100 non-null    object\n",
            " 14  review_date        100 non-null    object\n",
            "dtypes: int64(7), object(8)\n",
            "memory usage: 11.8+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(newdf.isnull().sum(),'/n')\n",
        "print('Duplication :',newdf.duplicated().sum())\n",
        "print(newdf.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a function to generate review embeddings:\n",
        "Tokenizes the text using the **BertTokenizer** and generates the embeddings using the **BertModel**\n",
        "The with **torch.no_grad()** context manager is used to avoid storing intermediate values in memory, which saves memory usage"
      ],
      "metadata": {
        "id": "G2KZMZDpuN3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Group the reviews by product ID and user ID, and generate embeddings for each group:\n",
        "\n",
        "\n",
        "Groups the reviews in the reviews_df dataframe by the \n",
        "**product_id** and **customer_id** columns\n",
        "\n",
        "Generates **review embeddings** for each review in the group using the get_review_embedding function defined earlier\n",
        "Stores the review embeddings in a dictionary called **product_embeddings**\n",
        "\n",
        "Modify the product_embeddings dictionary to store the embeddings for each user as a list of tuples: Replaces the list of embeddings for each user in the product_embeddings dictionary with a list of tuples containing the user ID and their embeddings.\n",
        "\n"
      ],
      "metadata": {
        "id": "lpVCY1UEyr_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_review_embedding(review_text):\n",
        "    # Tokenize the text\n",
        "    input_ids = torch.tensor([tokenizer.encode(str(review_text), truncation=True, max_length=256, add_special_tokens=True)]).to(device)  # Move input_ids to the GPU\n",
        "    # Generate the embeddings\n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = model(input_ids)[0]\n",
        "    review_embedding = torch.mean(last_hidden_states, dim=1).squeeze().cpu().numpy()  # Move tensor to CPU and convert to NumPy array\n",
        "    return review_embedding"
      ],
      "metadata": {
        "id": "Gn2aI_RGecJa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GNKpHdSnumOs"
      },
      "outputs": [],
      "source": [
        "# Group the reviews by product ID and user ID, and generate embeddings for each group\n",
        "product_reviews = newdf.groupby(['product_id', 'customer_id'])['review_body'].apply(list)\n",
        "product_embeddings = {}\n",
        "for (product_id, user_id), reviews in product_reviews.items():\n",
        "    review_embeddings = []\n",
        "    for review in reviews:\n",
        "        review_embedding = get_review_embedding(review)\n",
        "        review_embeddings.append(torch.tensor(review_embedding).to(device))  # Move review embeddings to the GPU\n",
        "    product_embeddings.setdefault(product_id, {}).setdefault(user_id, review_embeddings)\n",
        "\n",
        "# Modify the product_embeddings dictionary to store the embeddings for each user as a list of tuples\n",
        "for product_id, user_embeddings in product_embeddings.items():\n",
        "    product_embeddings[product_id] = [(user_id, [embedding.to(device) for embedding in embeddings]) for user_id, embeddings in user_embeddings.items()]\n",
        "# Create a list of embeddings in the desired format\n",
        "product_embeddings_list = []\n",
        "\n",
        "for product_id, user_embeddings in product_embeddings.items():\n",
        "    user_embeddings_list = []\n",
        "\n",
        "    for user_id, embeddings in user_embeddings:\n",
        "        embeddings_np = [embedding.detach().cpu().numpy().tolist() for embedding in embeddings]\n",
        "        user_embeddings_list.append((user_id, embeddings_np))\n",
        "\n",
        "    product_embeddings_list.append([product_id, user_embeddings_list])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product_embeddings_list[0]"
      ],
      "metadata": {
        "id": "K4qulcI_QsLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_embeddings_df = pd.DataFrame(product_embeddings_list, columns=['product_id', 'user_embeddings_list'])"
      ],
      "metadata": {
        "id": "tq5AFp9HS_e_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf = pd.merge(newdf, product_embeddings_df, on='product_id', how='left')"
      ],
      "metadata": {
        "id": "6IffRmb5UB29"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bQYIBbrRRef",
        "outputId": "9117bf15-af74-40c5-97b4-df312c2d938e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdf.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "0OS3LwAyUIgM",
        "outputId": "dbb77e75-b1e0-472a-f2f9-274c6ee676ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
              "0          US      1797882  R3I2DHQBR577SS  B001ANOOOE         2102612   \n",
              "1          US     18381298  R1QNE9NQFJC2Y4  B0016J22EQ       106393691   \n",
              "\n",
              "                                       product_title product_category  \\\n",
              "0  The Naked Bee Vitmin C Moisturizing Sunscreen ...           Beauty   \n",
              "1      Alba Botanica Sunless Tanning Lotion, 4 Ounce           Beauty   \n",
              "\n",
              "   star_rating  helpful_votes  total_votes  vine  verified_purchase  \\\n",
              "0            5              0            0     0                  1   \n",
              "1            5              0            0     0                  1   \n",
              "\n",
              "             review_headline  \\\n",
              "0                 Five Stars   \n",
              "1  Thank you Alba Bontanica!   \n",
              "\n",
              "                                         review_body review_date  \\\n",
              "0                   Love this, excellent sun block!!  2015-08-31   \n",
              "1  The great thing about this cream is that it do...  2015-08-31   \n",
              "\n",
              "                                user_embeddings_list  \n",
              "0  [(1797882, [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
              "1  [(18381298, [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc260e2a-a9e8-4a80-b80f-ff36aef8534f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>user_embeddings_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>1797882</td>\n",
              "      <td>R3I2DHQBR577SS</td>\n",
              "      <td>B001ANOOOE</td>\n",
              "      <td>2102612</td>\n",
              "      <td>The Naked Bee Vitmin C Moisturizing Sunscreen ...</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Love this, excellent sun block!!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>[(1797882, [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>18381298</td>\n",
              "      <td>R1QNE9NQFJC2Y4</td>\n",
              "      <td>B0016J22EQ</td>\n",
              "      <td>106393691</td>\n",
              "      <td>Alba Botanica Sunless Tanning Lotion, 4 Ounce</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Thank you Alba Bontanica!</td>\n",
              "      <td>The great thing about this cream is that it do...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>[(18381298, [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc260e2a-a9e8-4a80-b80f-ff36aef8534f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc260e2a-a9e8-4a80-b80f-ff36aef8534f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc260e2a-a9e8-4a80-b80f-ff36aef8534f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting review embeddings to tensors: The purpose of this code is to convert the review embeddings in the 'review_embeddings' column of df into PyTorch tensors. It first uses the apply() method with a lambda function to convert the string representation of the embeddings to a Python list using ast.literal_eval(), if the value is a string. Then, it applies another lambda function to convert each list of embeddings to a PyTorch tensor using torch.tensor(). The reshape(1, -1) call reshapes the tensor to have a single row and an inferred number of columns."
      ],
      "metadata": {
        "id": "kU9SotXt3O3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Normalizing review embeddings (optional):\n",
        "The purpose of this code is to normalize the review embeddings in the 'review_embeddings' column of df\n",
        "The fit_transform() method of the StandardScaler scales the embeddings using their mean and standard deviation. This code assumes that the 'review_embeddings' column contains numerical data."
      ],
      "metadata": {
        "id": "jUnKvH9o3WS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting user_id and item_id to categorical variables: \n",
        "The purpose of this code is to convert the 'user_id' and 'item_id' columns in df into categorical variables. It uses the pd.Categorical function from the pandas library to convert the columns to a categorical data type. Categorical variables are used to represent discrete values with a limited number of unique values."
      ],
      "metadata": {
        "id": "u0CGCHge3rb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping categorical variables to integer indices:\n",
        "The purpose of this code is to map the categorical variables 'user_id' and 'item_id' in df to integer indices. It uses the cat.codes attribute of the categorical columns to assign a unique integer index to each unique category. The mapped integer indices are stored in new columns named 'user_index' and 'item_index' respectively. This mapping is useful when working with recommendation models that require integer indices for users and items instead of categorical labels."
      ],
      "metadata": {
        "id": "_KyBM_9B3t9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert review embeddings to tensors and reshape\n",
        "for product_data in product_embeddings_list:\n",
        "    user_embeddings = product_data[1]  # List of (user, embeddings) pairs\n",
        "    for i in range(len(user_embeddings)):\n",
        "        embeddings = user_embeddings[i][1]  # List of embeddings\n",
        "        reshaped_embeddings = [torch.tensor(embedding).reshape(1, -1) for embedding in embeddings]\n",
        "        user_embeddings[i] = (user_embeddings[i][0], reshaped_embeddings)\n"
      ],
      "metadata": {
        "id": "fbLs8xRiLo4s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize review embeddings\n",
        "scaler = StandardScaler()\n",
        "for product_data in product_embeddings_list:\n",
        "    user_embeddings = product_data[1]  # List of (user, embeddings) pairs\n",
        "    for i in range(len(user_embeddings)):\n",
        "        embeddings = user_embeddings[i][1]  # List of embeddings\n",
        "        normalized_embeddings = [scaler.fit_transform(embedding) for embedding in embeddings]\n",
        "        user_embeddings[i] = (user_embeddings[i][0], normalized_embeddings)\n"
      ],
      "metadata": {
        "id": "grQD0O4aLzc1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = []\n",
        "item_ids = []\n",
        "user_indices = []\n",
        "item_indices = []\n",
        "\n",
        "# Iterate over the product_embeddings_list\n",
        "for product_data in product_embeddings_list:\n",
        "    user_embeddings = product_data[1]  # List of (user, embeddings) pairs\n",
        "    for user_id, embeddings in user_embeddings:\n",
        "        user_ids.append(user_id)\n",
        "        item_ids.append(product_data[0])  # Product ID\n",
        "        user_indices.append(len(user_ids) - 1)\n",
        "        item_indices.append(len(item_ids) - 1)\n",
        "\n",
        "# Assign the new values to the columns in the existing DataFrame\n",
        "newdf['user_id'] = user_ids\n",
        "newdf['item_id'] = item_ids\n",
        "newdf['user_index'] = user_indices\n",
        "newdf['item_index'] = item_indices\n"
      ],
      "metadata": {
        "id": "ALiMb_M4NGCZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "giLASVdjNk-U",
        "outputId": "92961bd7-3d7c-4d8d-ba90-874ea74ba53c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
              "0          US      1797882  R3I2DHQBR577SS  B001ANOOOE         2102612   \n",
              "1          US     18381298  R1QNE9NQFJC2Y4  B0016J22EQ       106393691   \n",
              "\n",
              "                                       product_title product_category  \\\n",
              "0  The Naked Bee Vitmin C Moisturizing Sunscreen ...           Beauty   \n",
              "1      Alba Botanica Sunless Tanning Lotion, 4 Ounce           Beauty   \n",
              "\n",
              "   star_rating  helpful_votes  total_votes  vine  verified_purchase  \\\n",
              "0            5              0            0     0                  1   \n",
              "1            5              0            0     0                  1   \n",
              "\n",
              "             review_headline  \\\n",
              "0                 Five Stars   \n",
              "1  Thank you Alba Bontanica!   \n",
              "\n",
              "                                         review_body review_date  \\\n",
              "0                   Love this, excellent sun block!!  2015-08-31   \n",
              "1  The great thing about this cream is that it do...  2015-08-31   \n",
              "\n",
              "                                user_embeddings_list   user_id     item_id  \\\n",
              "0  [(1797882, [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  30688607  B000094ZDX   \n",
              "1  [(18381298, [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0...  12650290  B000FRWNL2   \n",
              "\n",
              "   user_index  item_index  \n",
              "0           0           0  \n",
              "1           1           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60215d82-0eaf-47d2-94d2-6f4d6bfc997f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>user_embeddings_list</th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>user_index</th>\n",
              "      <th>item_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>1797882</td>\n",
              "      <td>R3I2DHQBR577SS</td>\n",
              "      <td>B001ANOOOE</td>\n",
              "      <td>2102612</td>\n",
              "      <td>The Naked Bee Vitmin C Moisturizing Sunscreen ...</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Love this, excellent sun block!!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>[(1797882, [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
              "      <td>30688607</td>\n",
              "      <td>B000094ZDX</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>18381298</td>\n",
              "      <td>R1QNE9NQFJC2Y4</td>\n",
              "      <td>B0016J22EQ</td>\n",
              "      <td>106393691</td>\n",
              "      <td>Alba Botanica Sunless Tanning Lotion, 4 Ounce</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Thank you Alba Bontanica!</td>\n",
              "      <td>The great thing about this cream is that it do...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>[(18381298, [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0...</td>\n",
              "      <td>12650290</td>\n",
              "      <td>B000FRWNL2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60215d82-0eaf-47d2-94d2-6f4d6bfc997f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60215d82-0eaf-47d2-94d2-6f4d6bfc997f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60215d82-0eaf-47d2-94d2-6f4d6bfc997f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the data into training and testing sets"
      ],
      "metadata": {
        "id": "CLBbtquu3y0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test_size parameter is set to 0.2, indicating that 20% of the data will be used for testing, and the remaining 80% will be used for training.\n",
        "The **random_state** parameter is set to **42**, which is used as a seed value for the random number generator.  This ensures that the data will be split in the same way each time the code is executed, allowing for reproducibility of results."
      ],
      "metadata": {
        "id": "8JxD4b6a4H6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(newdf, test_size=0.2, random_state=42)  # Adjust the test_size as desired\n"
      ],
      "metadata": {
        "id": "k7BQ0enGvWjB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "YbLOxb5udskl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class definition: BERT4Rec\n",
        "\n"
      ],
      "metadata": {
        "id": "wicMUXrpwQ9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this code is to define a PyTorch module called BERT4Rec for a recommendation model that incorporates BERT embeddings. "
      ],
      "metadata": {
        "id": "_HnlN2qP4dWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.Module Inheritance:**\n",
        "The class BERT4Rec inherits from the nn.Module class, which is the base class for all neural network modules in PyTorch."
      ],
      "metadata": {
        "id": "Rb6BlFT64u8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Constructor**:\n",
        "\n",
        "The __init__ method is the constructor of the BERT4Rec class.\n",
        "Parameters:\n",
        "\n",
        "**num_users**: The number of unique users in the recommendation system.\n",
        "\n",
        "**num_items**: The number of unique items in the recommendation system.\n",
        "\n",
        "**embedding_dim**: The dimensionality of the user and item embeddings.\n",
        "\n",
        "**review_embedding_dim**: The dimensionality of the review embeddings.\n",
        "\n",
        "**regularization_strength**: The strength of regularization to control overfitting.\n",
        "\n",
        "###Attribute Initialization:\n",
        "\n",
        "**user_embedding**: An embedding layer for users, using nn.Embedding with num_users as the number of unique users and embedding_dim as the embedding dimensionality.\n",
        "\n",
        "**item_embedding**: An embedding layer for items, using nn.Embedding with num_items as the number of unique items and embedding_dim as the embedding dimensionality.\n",
        "\n",
        "**item_transform**: A linear layer to transform the item embeddings to match the review_embedding_dim dimensionality.\n",
        "fc: A linear layer that takes concatenated user and item embeddings as input and produces a single output for recommendation.\n",
        "\n",
        "**review_embedding_dim**: Stores the value of \n",
        "review_embedding_dim for future reference within the class.\n",
        "\n",
        "**regularization_strength**: Stores the value of regularization_strength for future reference within the class.\n",
        "\n",
        "### Summary of Model Architecture:\n",
        "\n",
        "The model architecture combines user and item embeddings with a review embedding to make recommendations.\n",
        "The user and item embeddings are learned through the embedding layers (user_embedding and item_embedding).\n",
        "The item embeddings are then transformed using the item_transform linear layer to match the review_embedding_dim dimensionality.\n",
        "The transformed item embeddings and the user embeddings are concatenated.\n",
        "The concatenated tensor is passed through the fc linear layer to produce a single output for recommendation.\n",
        "The model aims to learn the relationships between users, items, and reviews to make accurate recommendations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4_SBXnbA4yBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT4Rec(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim, review_embedding_dim, regularization_strength):\n",
        "        super(BERT4Rec, self).__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "        self.item_transform = nn.Linear(embedding_dim, review_embedding_dim)  # Linear layer to transform item embedding size\n",
        "        self.fc = nn.Linear(review_embedding_dim +embedding_dim, 1)\n",
        "        self.review_embedding_dim = review_embedding_dim\n",
        "        self.regularization_strength = regularization_strength\n",
        "\n",
        "    def forward(self, user_indices, item_indices, review_embeddings):\n",
        "        user_embedded = self.user_embedding(user_indices)\n",
        "        item_embedded = self.item_embedding(item_indices)\n",
        "        review_embeddings = review_embeddings.squeeze()\n",
        "        review_embeddings = review_embeddings.type(torch.float32)\n",
        "        # Regularization term\n",
        "        item_transformed = self.item_transform(item_embedded)\n",
        "        item_regularized = self.regularization_strength * review_embeddings\n",
        "        item_regularized = item_transformed + item_regularized\n",
        "\n",
        "        concatenated = torch.cat((user_embedded,item_regularized), dim=1)\n",
        "\n",
        "        output = self.fc(concatenated) \n",
        "        return output\n",
        "\n",
        "# Set hyperparameters\n",
        "embedding_dim = 64\n",
        "review_embedding_dim = 768  # Update the value according to the size of your review embeddings\n",
        "learning_rate = 0.001\n",
        "num_epochs = 15\n",
        "batch_size = 32\n",
        "regularization_strength = 0.003\n",
        "num_items = len(newdf['item_index'].unique())\n",
        "num_users = len(newdf['user_index'].unique())\n",
        "\n",
        "\n",
        "# Instantiate the BERT4Rec model\n",
        "model = BERT4Rec(num_users=num_users,\n",
        "                 num_items=num_items,\n",
        "                 embedding_dim=embedding_dim,\n",
        "                 review_embedding_dim=review_embedding_dim,\n",
        "                 regularization_strength=regularization_strength)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# Convert tensors to PyTorch data types\n",
        "train_user_indices = torch.LongTensor(train_data['user_index'].values)\n",
        "train_item_indices = torch.LongTensor(train_data['item_index'].values)\n",
        "# Convert review embeddings to tensors\n",
        "\n",
        "train_review_embeddings = torch.stack([torch.tensor(embeddings[0][1]) for embeddings in train_data['user_embeddings_list'].values])\n",
        "\n",
        "train_ratings = torch.FloatTensor(train_data['star_rating'].values)\n",
        "\n",
        "# Create data loader for batching\n",
        "train_dataset = torch.utils.data.TensorDataset(train_user_indices, train_item_indices, train_review_embeddings, train_ratings)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for batch_user_indices, batch_item_indices, batch_review_embeddings, batch_ratings in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(user_indices=batch_user_indices, item_indices=batch_item_indices, review_embeddings=batch_review_embeddings)\n",
        "        loss = criterion(outputs.squeeze(), batch_ratings)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * batch_user_indices.size(0)\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_data)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-I4gY5jwZj-",
        "outputId": "f12213e9-8ef8-4a01-cd5a-bf20580e2ac8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 20.139391326904295\n",
            "Epoch 2/15, Loss: 16.712335968017577\n",
            "Epoch 3/15, Loss: 14.220412826538086\n",
            "Epoch 4/15, Loss: 12.118376159667969\n",
            "Epoch 5/15, Loss: 10.269171714782715\n",
            "Epoch 6/15, Loss: 8.652211761474609\n",
            "Epoch 7/15, Loss: 7.328273963928223\n",
            "Epoch 8/15, Loss: 6.236619758605957\n",
            "Epoch 9/15, Loss: 5.336564254760742\n",
            "Epoch 10/15, Loss: 4.602384281158447\n",
            "Epoch 11/15, Loss: 3.953199100494385\n",
            "Epoch 12/15, Loss: 3.5007971048355104\n",
            "Epoch 13/15, Loss: 3.0232475280761717\n",
            "Epoch 14/15, Loss: 2.645865035057068\n",
            "Epoch 15/15, Loss: 2.2982677936553957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Method: forward\n",
        "The forward method is the implementation of the forward pass for the BERT4Rec model. It defines how the input tensors are processed through the layers of the model to generate the output.\n",
        "\n"
      ],
      "metadata": {
        "id": "EducDuR55yvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameters**:\n",
        "\n",
        "**user_indices**: Tensor containing the indices of the users for the current batch.\n",
        "\n",
        "**item_indices**: Tensor containing the indices of the items for the current batch.\n",
        "\n",
        "**review_embeddings**: Tensor containing the review embeddings for the current batch."
      ],
      "metadata": {
        "id": "DV5NO4zY505m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forward Pass:**\n",
        "**user_embedded**: Embeds the user indices using the user_embedding layer.\n",
        "\n",
        "**item_embedded**: Embeds the item indices using the item_embedding layer.\n",
        "\n",
        "**review_embeddings**: Squeezes the review embeddings tensor to remove any unnecessary dimensions.\n",
        "\n",
        "**review_embeddings**: Converts the data type of the squeezed review embeddings tensor to torch.float32.\n",
        "\n",
        "**item_transformed**: Passes the item embeddings through the item_transform linear layer to match the review_embedding_dim dimensionality.\n",
        "\n",
        "**item_regularized**: Computes the regularization term by multiplying the review embeddings by the regularization_strength and adding it to the transformed item embeddings.\n",
        "\n",
        "**concatenated**: Concatenates the user embeddings and the regularized item embeddings along the second dimension (column-wise concatenation).\n",
        "\n",
        "**output**: Passes the concatenated tensor through the fc linear layer to produce the final recommendation output.\n",
        "\n",
        "### Summary of Forward() Method\n",
        "This forward method defines the flow of data through the model's layers and computes the recommendation output. It is called automatically when the model is invoked with the input data during training or inference."
      ],
      "metadata": {
        "id": "WC9oZDHn6EGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Hyperparameters:\n",
        "**embedding_dim**: The dimensionality of the user and item embeddings. It is set to 64 in this example.\n",
        "\n",
        "**review_embedding_dim**: The dimensionality of the review embeddings. This value needs to match the dimensionality of the review embeddings used in the model architecture.\n",
        "\n",
        "**learning_rate**: The learning rate used by the optimizer during training. It is set to 0.001.\n",
        "\n",
        "**num_epochs**: The number of training epochs, which determines how many times the model will iterate over the entire training dataset. It is set to 15.\n",
        "\n",
        "**batch_size**: The number of samples per batch during training. It controls how many samples are processed together in each forward and backward pass. It is set to 32.\n",
        "\n",
        "**regularization_strength**: The strength of regularization applied to the item embeddings. It controls the impact of the regularization term on the item embeddings during training. It is set to 0.003.\n",
        "\n",
        "**num_items**: The number of unique items in the dataset. It is calculated based on the number of unique item indices in the 'item_index' column of the DataFrame.\n",
        "\n",
        "**num_users**: The number of unique users in the dataset. It is calculated based on the number of unique user indices in the 'user_index' column of the DataFrame.\n"
      ],
      "metadata": {
        "id": "ABs3tt6REj2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instantiating the BERT4Rec Model:\n",
        "\n",
        "The code creates an instance of the BERT4Rec model by passing the necessary parameters to the constructor. The parameters include num_users, num_items, embedding_dim, review_embedding_dim, and regularization_strength that were defined earlier.\n"
      ],
      "metadata": {
        "id": "PlmAMQsoE3ry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining Loss Function and Optimizer:\n",
        "The code defines the loss function (**criterion**) and the optimizer (**optimizer**) for training the model. The mean squared error (**nn.MSELoss**) is used as the loss function, and the Adam optimizer (**optim.Adam**) is used with the specified learning rate (**learning_rate**) and the model's parameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q7i1mqLGFT98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Data Loader for Batching:\n",
        "\n",
        "The code creates a data loader (train_loader) that takes the training tensors (train_user_indices, train_item_indices, train_review_embeddings, train_ratings) and generates batches of data for training. The data loader is created using torch.utils.data.TensorDataset and torch.utils.data.DataLoader, and it shuffles the data (shuffle=True) to ensure randomization during training. The batch size is set to the specified batch_size"
      ],
      "metadata": {
        "id": "fW4tjTBCFjAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop:\n",
        "\n"
      ],
      "metadata": {
        "id": "EEKThseGF7_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "This loop iterates over each epoch, starting from 0 and up to num_epochs.\n",
        "running_loss = 0.0:\n",
        "\n",
        "This variable is used to keep track of the running loss for each epoch.\n",
        "for batch_user_indices, batch_item_indices, batch_review_embeddings, batch_ratings in train_loader:\n",
        "\n",
        "This loop iterates over each batch of training data generated by the train_loader.\n",
        "\n",
        "The loop variables represent the user indices (batch_user_indices), item indices (batch_item_indices), review embeddings (batch_review_embeddings), and ratings (batch_ratings) for the current batch.\n",
        "\n",
        "optimizer.zero_grad():\n",
        "\n",
        "Clears the gradients of the model parameters before computing the gradients for the current batch."
      ],
      "metadata": {
        "id": "BKrGjDjPGLsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**outputs** = model(user_indices=batch_user_indices, item_indices=batch_item_indices, review_embeddings=batch_review_embeddings):\n",
        "\n",
        "Calls the forward method of the model to compute the recommendation outputs for the current batch of data.\n",
        "Passes the batched user indices, item indices, and review embeddings as inputs to the model.\n",
        "\n",
        "loss = criterion(outputs.squeeze(), batch_ratings):\n",
        "Computes the loss between the recommendation outputs (outputs) and the batch ratings (batch_ratings).\n",
        "The squeeze method is used to remove any unnecessary dimensions from the outputs tensor.\n",
        "\n",
        "loss.backward():\n",
        "Backpropagates the gradients of the loss through the model's parameters, computing the gradients for each parameter.\n",
        "\n",
        "optimizer.step():\n",
        "Updates the model's parameters based on the computed gradients using the specified optimizer (optimizer).\n",
        "\n",
        "running_loss += loss.item() * batch_user_indices.size(0):\n",
        "Updates the running loss by adding the current batch's loss multiplied by the batch size (batch_user_indices.size(0)).\n",
        "This helps calculate the average loss per sample in the epoch.\n",
        "\n",
        "epoch_loss = running_loss / len(train_data):\n",
        "Computes the average loss per sample for the entire training dataset in the current epoch.\n",
        "\n",
        "print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\"):\n",
        "Prints the epoch number and the average loss per sample for the current epoch.\n"
      ],
      "metadata": {
        "id": "nwJ9XfKHGXmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary of Training Loop\n",
        "The training loop iterates over the epochs and batches, performs forward and backward passes, updates the model's parameters, and computes the loss. At the end of each epoch, it prints the average loss for monitoring the training progress."
      ],
      "metadata": {
        "id": "T9Q9eTkMGcTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics - MSE"
      ],
      "metadata": {
        "id": "AC_IDf3BHxsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tensors to PyTorch data types\n",
        "test_user_indices = torch.LongTensor(test_data['user_index'].values)\n",
        "test_item_indices = torch.LongTensor(test_data['item_index'].values)\n",
        "test_review_embeddings = torch.stack([torch.tensor(embeddings[0][1]) for embeddings in test_data['user_embeddings_list'].values])\n",
        "#test_review_embeddings = torch.stack(test_review_embeddings)\n",
        "test_ratings = torch.FloatTensor(test_data['star_rating'].values)\n",
        "\n",
        "# Calculate predictions\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(test_user_indices, test_item_indices, test_review_embeddings)\n",
        "    test_predictions = test_outputs.squeeze().cpu().numpy()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "# Example: Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(test_ratings, test_predictions)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "AIAleWqovceC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a14cf8-91b8-4219-afcc-a7a8c5756cc2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 20.666584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Score"
      ],
      "metadata": {
        "id": "9cGGq3qBGhnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Converting Data to PyTorch Tensors:\n",
        "\n",
        "Similar to the training data, the code converts the test data into PyTorch tensor format. The user indices (test_user_indices), item indices (test_item_indices), review embeddings (test_review_embeddings), and ratings (test_ratings) are converted to the appropriate tensor types (torch.LongTensor and torch.FloatTensor).\n",
        "\n",
        "###Calculating Predictions:\n",
        "\n",
        "The test data is passed through the trained model to generate predictions. The model is called with the test user indices, item indices, and review embeddings to obtain the recommendation outputs (test_outputs).\n",
        "The squeeze method is applied to remove unnecessary dimensions from the outputs.\n",
        "The predictions are then extracted from the tensors, converted to a NumPy array (test_predictions), and moved to the CPU.\n",
        "\n",
        "###Calculating Evaluation Metrics:\n",
        "\n",
        "In this example, the Mean Squared Error (MSE) metric is calculated as an evaluation metric.\n",
        "The mean_squared_error function from the scikit-learn library is used to compute the MSE between the test ratings (test_ratings) and the predicted ratings (test_predictions).\n",
        "The calculated MSE is stored in the variable mse.\n",
        "Finally, the MSE value obtained is approximately 11.948236."
      ],
      "metadata": {
        "id": "3WR-BPZSGshM"
      }
    }
  ]
}